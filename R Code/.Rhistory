myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Decision Tree ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
dtree_fit <- train(Status_der ~ ., data = train_total, method = "rpart",
parms = list(split = "information"),
trControl=trctrl,
tuneLength = 10)
prp(dtree_fit$finalModel, box.palette = "Reds", tweak = 1.2)
myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Decision Tree ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
dtree_fit <- train(Status_der ~ ., data = train_total, method = "rpart",
parms = list(split = "information"),
trControl=trctrl,
tuneLength = 10)
prp(dtree_fit$finalModel, box.palette = "Reds", tweak = 1.2)
myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Decision Tree ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
dtree_fit <- train(Status_der ~ ., data = train_total, method = "rpart",
parms = list(split = "information"),
trControl=trctrl,
tuneLength = 10)
prp(dtree_fit$finalModel, box.palette = "Reds", tweak = 1.2)
library("ggplot2")
library("tree")
library("caret")
library("ROCR")
library("data.table")
library("dplyr")
library("pscl")
library("MASS")
library("e1071")
library("rpart.plot")
myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Decision Tree ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
dtree_fit <- train(Status_der ~ ., data = train_total, method = "rpart",
parms = list(split = "information"),
trControl=trctrl,
tuneLength = 10)
prp(dtree_fit$finalModel, box.palette = "Reds", tweak = 1.2)
test_pred <- predict(dtree_fit, newdata = test_total)
confusionMatrix(test_pred, test_total$Status_der )  #check accuracy
test_pred <- predict(dtree_fit, newdata = test_total)
confusionMatrix(test_pred, test_total$Status_der )  #check accuracy
library("data.table")
library("dplyr")
library("pscl")
library("caret")
library("ROCR")
require("MASS")
library("data.table")
library("dplyr")
library("pscl")
library("caret")
library("ROCR")
require("MASS")
myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
write.csv(dis_mydata_subset,'dis_mydata_subset.csv')
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Logistic Regression ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
## Model 1 - With all variables
model <- glm (Status_der ~ .
, data = train_total, family = binomial)
summary(model)
best_model <- stepAIC (model, trace = FALSE)
best_model$anova
forward_model <- stepAIC(model,direction = "forward", trace = FALSE)
forward_model$anova
backward_model <- stepAIC(model,direction = "backward", trace = FALSE)
backward_model$anova
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test_total$Status_der)
print(paste('Accuracy',1-misClasificError))
########### Total Accuracy on whole data is 92.43% #########################
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results_overalldata > 0.5,1,0)
library("data.table")
library("dplyr")
library("pscl")
library("caret")
library("ROCR")
require("MASS")
myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
write.csv(dis_mydata_subset,'dis_mydata_subset.csv')
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Logistic Regression ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
## Model 1 - With all variables
model <- glm (Status_der ~ .
, data = train_total, family = binomial)
summary(model)
best_model <- stepAIC (model, trace = FALSE)
best_model$anova
forward_model <- stepAIC(model,direction = "forward", trace = FALSE)
forward_model$anova
backward_model <- stepAIC(model,direction = "backward", trace = FALSE)
backward_model$anova
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test_total$Status_der)
print(paste('Accuracy',1-misClasificError))
########### Total Accuracy on whole data is 92.43% #########################
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results$overalldata > 0.5,1,0)
library("data.table")
library("dplyr")
library("pscl")
library("caret")
library("ROCR")
require("MASS")
myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
write.csv(dis_mydata_subset,'dis_mydata_subset.csv')
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Logistic Regression ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
## Model 1 - With all variables
model <- glm (Status_der ~ .
, data = train_total, family = binomial)
summary(model)
best_model <- stepAIC (model, trace = FALSE)
best_model$anova
forward_model <- stepAIC(model,direction = "forward", trace = FALSE)
forward_model$anova
backward_model <- stepAIC(model,direction = "backward", trace = FALSE)
backward_model$anova
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test_total$Status_der)
print(paste('Accuracy',1-misClasificError))
########### Total Accuracy on whole data is 92.43% #########################
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results$test_total > 0.5,1,0)
myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
write.csv(dis_mydata_subset,'dis_mydata_subset.csv')
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Logistic Regression ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
## Model 1 - With all variables
model <- glm (Status_der ~ .
, data = train_total, family = binomial)
summary(model)
best_model <- stepAIC (model, trace = FALSE)
best_model$anova
forward_model <- stepAIC(model,direction = "forward", trace = FALSE)
forward_model$anova
backward_model <- stepAIC(model,direction = "backward", trace = FALSE)
backward_model$anova
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test_total$Status_der)
print(paste('Accuracy',1-misClasificError))
########### Total Accuracy on whole data is 92.43% #########################
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError_overall <- mean(fitted.results != test_total$Status_der)
print(paste('Accuracy',1-misClasificError_overall))
####################################################################################################
############       Segeregating data based on dealer Category      #################################
####################################################################################################
agg_agency_data <- aggregate(dis_mydata_subset$Status_der,
by=list(Category=dis_mydata_subset$Dlr.Code), FUN=sum)
myData = read.csv("C:\\Users\\Yash\\Desktop\\ISB Documents\\Capstone Project\\Data\\Raj Data\\Raj_data_for_EDA.csv",header=TRUE)
######################################################################
############# Data Cleaning ##########################################
######################################################################
## Removing last columns
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
myData <- myData[,-54]
## Removing first columns
myData <- myData[,-1]
myData <- myData[,-1]
a <- as.data.frame(myData)
b <- as.data.table(myData)
# Confirm dimensionality
dim(a)
dim(b)
# Unique rows using all columns
dim(unique(a))
dis_mydata <- as.data.frame(unique(a))
#dim(unique(b))
dis_mydata_u <- as.data.table(unique(b))
#dis_mydata %>%
#  select(dis_mydata$Dlr.Code, dis_mydata$Tehsil, dis_mydata$DSE )
dis_mydata_subset <- dis_mydata[, c(5,14,18,23,29,35)]
dis_mydata_subset$Status_der<-0
dis_mydata_subset$Status_der <- ifelse(dis_mydata_subset$Status > 3 |dis_mydata_subset$Status < 3 , 0, 1)
dis_mydata_subset$Status_der <- as.factor(dis_mydata_subset$Status_der)
write.csv(dis_mydata_subset,'dis_mydata_subset.csv')
dis_mydata_subset <- dis_mydata_subset[,-6]
######################################################################
############# Logistic Regression ####################################
######################################################################
############# Splitting data between Train and Test ##################
dt = sort(sample(nrow(dis_mydata_subset), nrow(dis_mydata_subset)*.7))
train_total<-dis_mydata_subset[dt,]
test_total<-dis_mydata_subset[-dt,]
## Model 1 - With all variables
model <- glm (Status_der ~ .
, data = train_total, family = binomial)
summary(model)
best_model <- stepAIC (model, trace = FALSE)
best_model$anova
forward_model <- stepAIC(model,direction = "forward", trace = FALSE)
forward_model$anova
backward_model <- stepAIC(model,direction = "backward", trace = FALSE)
backward_model$anova
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test_total$Status_der)
print(paste('Accuracy',1-misClasificError))
########### Total Accuracy on whole data is 92.43% #########################
fitted.results <- predict(model,newdata=test_total[,],type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError_overall <- mean(fitted.results != test_total$Status_der)
print(paste('Accuracy',1-misClasificError_overall))
####################################################################################################
############       Segeregating data based on dealer Category      #################################
####################################################################################################
agg_agency_data <- aggregate(dis_mydata_subset$Status_der,
by=list(Category=dis_mydata_subset$Dlr.Code), FUN=count)
